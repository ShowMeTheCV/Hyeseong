{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a7ae64",
   "metadata": {},
   "source": [
    "# 객체검출\n",
    "\n",
    "## 파이썬 객체 검출\n",
    "객체 검출 : 이미지에서 의미있는 개체를 탐지하는 알고리즘\n",
    "    - 검출 : 이미지에서 특정 클래스를 찾는 것\n",
    "    - 인식 : 검출된 대상이 어떤 객체인지 식별하는 것을 의미\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76b2f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "def download_images():\n",
    "    base_url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/test_images/'\n",
    "    filenames = ['image1.jpg', 'image2.jpg']\n",
    "    image_paths = []\n",
    "    for filename in filenames:\n",
    "        image_path = tf.keras.utils.get_file(fname=filename,\n",
    "                                            origin=base_url + filename,\n",
    "                                            untar=False)\n",
    "        image_path = pathlib.Path(image_path)\n",
    "        image_paths.append(str(image_path))\n",
    "    return image_paths\n",
    "\n",
    "IMAGE_PATHS = download_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c6849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract model\n",
    "def download_model(model_name, model_date):\n",
    "    base_url = 'http://download.tensorflow.org/models/object_detection/tf2/'\n",
    "    model_file = model_name + '.tar.gz'\n",
    "    model_dir = tf.keras.utils.get_file(fname=model_name,\n",
    "                                        origin=base_url + model_date + '/' + model_file,\n",
    "                                        untar=True)\n",
    "    return str(model_dir)\n",
    "\n",
    "MODEL_DATE = '20200711'\n",
    "MODEL_NAME = 'ssd_mobilenet_v2_320x320_coco17_tpu-8'\n",
    "PATH_TO_MODEL_DIR = download_model(MODEL_NAME, MODEL_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c34ac79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "# Download labels file\n",
    "def download_labels(filename):\n",
    "    base_url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/'\n",
    "    label_dir = tf.keras.utils.get_file(fname=filename,\n",
    "                                        origin=base_url + filename,\n",
    "                                        untar=False)\n",
    "    label_dir = pathlib.Path(label_dir)\n",
    "    return str(label_dir)\n",
    "\n",
    "LABEL_FILENAME = 'mscoco_label_map.pbtxt'\n",
    "PATH_TO_LABELS = download_labels(LABEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a7326c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done! Took 9.32922887802124 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# from object_detection.utils import label_map_util\n",
    "# from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b760371",
   "metadata": {},
   "source": [
    "## 텐서플로우\n",
    "> Q1. tf.version 명령을 통해 설치된 텐서플로우 버전을 확인해봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "325e2efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow._api.v2.version' from '/home/aiffel-dj63/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/_api/v2/version/__init__.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001e7cc2",
   "metadata": {},
   "source": [
    "> Q2. 이 예제에서는 SSD MobileNet v2 320x320 모델을 사용합니다. 해당 모델을 다운로드해봅시다.\n",
    "\n",
    "https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\n",
    "\n",
    "\n",
    "> Q3. 마찬가지로, 객체 이름을 표시하기 위해 라벨 파일이 저장된 페이지를 방문하여 라벨 맵을 다운로드해봅시다.\n",
    "\n",
    "https://github.com/tensorflow/models/tree/master/research/object_detection/data\n",
    "\n",
    "\n",
    "> Q4. 예제 9.2(그래프 정의) 를 참조하여 그래프를 읽어오세요.\n",
    "\n",
    "### 텐서변환 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "609db985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os \n",
    "\n",
    "model = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "capture = cv2.VideoCapture(os.getenv('HOME') + '/OpenCV/bird.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    if capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "        break\n",
    "\n",
    "    #---구판에만 있는 resize코드(아마 개정판이 되며 동영상 자체 사이즈를 수정했나봅니다.)--\n",
    "    #input_img = cv2.resize(frame, (300,300))\n",
    "    #-----------------------------------------------------------------------\n",
    "    input_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    input_tensor = tf.convert_to_tensor(input_img)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c8cf2c",
   "metadata": {},
   "source": [
    "### 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a11bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[64. 64. 64. 86. 49. 67. 67. 51. 67. 56. 50. 86. 47. 47. 56. 64.  1. 64.\n",
      " 64. 62.  1. 64. 64. 64. 61. 64. 86. 56. 53. 50. 64. 47. 64. 51. 46. 56.\n",
      " 86. 64. 56. 86. 64. 64. 67.  1. 48. 64.  1. 56. 51. 59. 86. 86. 56. 50.\n",
      " 86. 86. 64. 62. 47. 51. 44. 64. 64. 51. 64. 56. 64. 64. 49. 64. 47. 51.\n",
      " 64. 86. 64. 56. 86. 86.  1. 54. 46. 64. 86. 63.  1. 57. 46. 86. 47. 47.\n",
      " 64. 64. 62. 15.  1. 64. 44. 64. 56.  1.], shape=(100,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.45407227 0.44321972 0.385714   0.35693544 0.32927752 0.27169773\n",
      " 0.2630513  0.25060666 0.24908853 0.24881224 0.24601169 0.24532165\n",
      " 0.24185033 0.24025491 0.23745428 0.23200627 0.2248104  0.22283354\n",
      " 0.22207609 0.21521445 0.21046485 0.2096801  0.20884801 0.20369044\n",
      " 0.2017944  0.20018174 0.19629028 0.19234046 0.18856114 0.18456899\n",
      " 0.18396156 0.17573424 0.17548677 0.17506516 0.17423509 0.1731333\n",
      " 0.17213508 0.17143817 0.17016506 0.1699915  0.16862968 0.16749884\n",
      " 0.16661674 0.1660004  0.16388856 0.16208312 0.16121574 0.15908481\n",
      " 0.15818949 0.15793893 0.15775312 0.15493198 0.15221891 0.15017071\n",
      " 0.14927629 0.14899741 0.14778316 0.1469355  0.14630717 0.14621398\n",
      " 0.14569513 0.14565703 0.14557856 0.14374952 0.14298256 0.14193688\n",
      " 0.13955352 0.13853393 0.13751726 0.13487466 0.13449669 0.13306995\n",
      " 0.13240737 0.13227768 0.13210993 0.13154961 0.12969033 0.12924363\n",
      " 0.1287778  0.12856923 0.12833913 0.12613353 0.12509127 0.12473901\n",
      " 0.12458058 0.12437249 0.1238545  0.12291317 0.12215593 0.12192543\n",
      " 0.12149449 0.12132712 0.12132069 0.12065423 0.12052822 0.11898656\n",
      " 0.11890922 0.11882185 0.11858277 0.11853095], shape=(100,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[4.63073164e-01 1.85231864e-03 8.67354155e-01 1.47083923e-01]\n",
      " [7.57159591e-01 6.00729883e-02 9.98615265e-01 9.94305253e-01]\n",
      " [7.42942095e-01 1.29937679e-01 9.33442831e-01 3.06537390e-01]\n",
      " [5.10532200e-01 8.45161825e-03 8.50242555e-01 1.45328730e-01]\n",
      " [8.79299223e-01 0.00000000e+00 9.89627540e-01 2.72493362e-01]\n",
      " [1.70002609e-01 3.06318700e-02 9.72476602e-01 9.96420145e-01]\n",
      " [8.79299223e-01 0.00000000e+00 9.89627540e-01 2.72493362e-01]\n",
      " [7.53215432e-01 0.00000000e+00 8.60213876e-01 4.34041433e-02]\n",
      " [7.52429605e-01 2.69228816e-02 9.99999404e-01 1.00000000e+00]\n",
      " [7.37203479e-01 1.08017601e-01 9.08790708e-01 2.97964245e-01]\n",
      " [5.06773531e-01 1.30478963e-02 8.81231725e-01 1.42079949e-01]\n",
      " [7.53215432e-01 0.00000000e+00 8.60213876e-01 4.34041433e-02]\n",
      " [0.00000000e+00 4.70336497e-01 8.07329714e-01 9.90783274e-01]\n",
      " [7.53215432e-01 0.00000000e+00 8.60213876e-01 4.34041433e-02]\n",
      " [7.64548540e-01 9.27671790e-02 1.00000000e+00 9.86963689e-01]\n",
      " [4.68012333e-01 2.63930857e-02 9.89777565e-01 9.70809340e-01]\n",
      " [0.00000000e+00 4.70336497e-01 8.07329714e-01 9.90783274e-01]\n",
      " [4.87053126e-01 1.27472281e-02 9.19674397e-01 2.42700994e-01]\n",
      " [7.41536975e-01 1.67328447e-01 9.91444945e-01 3.68566066e-01]\n",
      " [5.10532200e-01 8.45161825e-03 8.50242555e-01 1.45328730e-01]\n",
      " [1.73493832e-01 3.32483053e-02 9.72825050e-01 9.95760679e-01]\n",
      " [7.45547950e-01 1.03248209e-01 9.94252384e-01 6.24546885e-01]\n",
      " [7.79396474e-01 4.20248508e-02 8.81117165e-01 1.22619539e-01]\n",
      " [7.53215432e-01 0.00000000e+00 8.60213876e-01 4.34041433e-02]\n",
      " [7.05092371e-01 2.08001435e-02 9.94321287e-01 9.86255169e-01]\n",
      " [8.64705324e-01 0.00000000e+00 9.91948366e-01 2.97121286e-01]\n",
      " [5.55045366e-01 4.97260094e-02 8.47986579e-01 1.65633351e-01]\n",
      " [8.23046267e-01 1.43250793e-01 9.14458811e-01 2.54518241e-01]\n",
      " [7.53215432e-01 0.00000000e+00 8.60213876e-01 4.34041433e-02]\n",
      " [8.79299223e-01 0.00000000e+00 9.89627540e-01 2.72493362e-01]\n",
      " [4.56336737e-01 3.72864306e-05 8.41493368e-01 9.14569199e-02]\n",
      " [7.79396474e-01 4.20248508e-02 8.81117165e-01 1.22619539e-01]\n",
      " [7.16959894e-01 8.72188807e-02 9.96997416e-01 4.11907643e-01]\n",
      " [8.79299223e-01 0.00000000e+00 9.89627540e-01 2.72493362e-01]\n",
      " [7.53215432e-01 0.00000000e+00 8.60213876e-01 4.34041433e-02]\n",
      " [8.25217903e-01 9.99146253e-02 8.98122013e-01 1.71045646e-01]\n",
      " [7.79396474e-01 4.20248508e-02 8.81117165e-01 1.22619539e-01]\n",
      " [7.47505307e-01 7.07127228e-02 9.06066537e-01 2.77210951e-01]\n",
      " [7.69399047e-01 5.72471842e-02 9.32560444e-01 3.01061928e-01]\n",
      " [7.05092371e-01 2.08001435e-02 9.94321287e-01 9.86255169e-01]\n",
      " [1.73493832e-01 3.32483053e-02 9.72825050e-01 9.95760679e-01]\n",
      " [8.14792037e-01 3.65974307e-02 9.95926142e-01 3.38675261e-01]\n",
      " [4.94059265e-01 0.00000000e+00 9.99915659e-01 9.78844702e-01]\n",
      " [1.44740343e-02 1.43408179e-02 7.83948064e-01 5.49360037e-01]\n",
      " [5.10532200e-01 8.45161825e-03 8.50242555e-01 1.45328730e-01]\n",
      " [7.82017708e-01 2.93304846e-02 9.49518681e-01 2.63933331e-01]\n",
      " [1.89257264e-02 1.75835341e-01 7.17210472e-01 8.53069425e-01]\n",
      " [8.18980575e-01 1.76568806e-01 9.09000635e-01 2.78875232e-01]\n",
      " [8.07776093e-01 2.61366144e-02 8.89669180e-01 1.20960914e-01]\n",
      " [7.05092371e-01 2.08001435e-02 9.94321287e-01 9.86255169e-01]\n",
      " [4.87053126e-01 1.27472281e-02 9.19674397e-01 2.42700994e-01]\n",
      " [7.37203479e-01 1.08017601e-01 9.08790708e-01 2.97964245e-01]\n",
      " [7.38934636e-01 1.44220233e-01 8.97814870e-01 2.55895585e-01]\n",
      " [5.55045366e-01 4.97260094e-02 8.47986579e-01 1.65633351e-01]\n",
      " [6.24857247e-01 6.37495294e-02 8.20814788e-01 1.13442682e-01]\n",
      " [8.07776093e-01 2.61366144e-02 8.89669180e-01 1.20960914e-01]\n",
      " [5.55045366e-01 4.97260094e-02 8.47986579e-01 1.65633351e-01]\n",
      " [5.55045366e-01 4.97260094e-02 8.47986579e-01 1.65633351e-01]\n",
      " [8.07776093e-01 2.61366144e-02 8.89669180e-01 1.20960914e-01]\n",
      " [7.37203479e-01 1.08017601e-01 9.08790708e-01 2.97964245e-01]\n",
      " [7.53215432e-01 0.00000000e+00 8.60213876e-01 4.34041433e-02]\n",
      " [4.72400486e-02 7.96207786e-03 9.15117860e-01 3.45523953e-01]\n",
      " [7.09431767e-01 1.22648105e-01 9.03897285e-01 2.66367793e-01]\n",
      " [7.05092371e-01 2.08001435e-02 9.94321287e-01 9.86255169e-01]\n",
      " [4.53174204e-01 2.16994435e-02 9.77695823e-01 5.19992471e-01]\n",
      " [7.53215432e-01 0.00000000e+00 8.60213876e-01 4.34041433e-02]\n",
      " [7.56682694e-01 1.01449773e-01 9.85499322e-01 2.61939406e-01]\n",
      " [1.27517074e-01 3.90565395e-03 8.87057543e-01 1.46008044e-01]\n",
      " [5.06773531e-01 1.30478963e-02 8.81231725e-01 1.42079949e-01]\n",
      " [8.07776093e-01 2.61366144e-02 8.89669180e-01 1.20960914e-01]\n",
      " [6.66791499e-02 3.01110148e-02 9.30896878e-01 9.89173472e-01]\n",
      " [7.79396474e-01 4.20248508e-02 8.81117165e-01 1.22619539e-01]\n",
      " [7.55802155e-01 1.11526400e-02 9.58238482e-01 1.58648357e-01]\n",
      " [5.25816083e-01 7.92708248e-04 8.63782287e-01 8.62421542e-02]\n",
      " [7.45673954e-01 1.56700879e-01 8.95653903e-01 2.79646695e-01]\n",
      " [7.39972830e-01 1.37515336e-01 9.21632886e-01 3.60477120e-01]\n",
      " [1.70002609e-01 3.06318700e-02 9.72476602e-01 9.96420145e-01]\n",
      " [5.47055781e-01 5.03895506e-02 6.45813763e-01 1.21479847e-01]\n",
      " [0.00000000e+00 1.77505612e-03 9.42557216e-01 1.29615173e-01]\n",
      " [8.79299223e-01 0.00000000e+00 9.89627540e-01 2.72493362e-01]\n",
      " [7.79396474e-01 4.20248508e-02 8.81117165e-01 1.22619539e-01]\n",
      " [4.13104594e-01 2.26399302e-03 6.90090001e-01 1.39796183e-01]\n",
      " [8.64705324e-01 0.00000000e+00 9.91948366e-01 2.97121286e-01]\n",
      " [7.57159591e-01 6.00729883e-02 9.98615265e-01 9.94305253e-01]\n",
      " [4.87113804e-01 5.93721122e-03 8.64613414e-01 1.52212650e-01]\n",
      " [9.06172931e-01 2.08752483e-01 9.53431904e-01 2.78336614e-01]\n",
      " [5.10532200e-01 8.45161825e-03 8.50242555e-01 1.45328730e-01]\n",
      " [8.18980575e-01 1.76568806e-01 9.09000635e-01 2.78875232e-01]\n",
      " [2.99833417e-02 5.09282351e-01 6.09559357e-01 7.92369962e-01]\n",
      " [2.68275738e-02 4.44886565e-01 6.07271194e-01 6.59828544e-01]\n",
      " [8.25217903e-01 9.99146253e-02 8.98122013e-01 1.71045646e-01]\n",
      " [3.46474767e-01 0.00000000e+00 9.93654728e-01 2.93445051e-01]\n",
      " [4.87053126e-01 1.27472281e-02 9.19674397e-01 2.42700994e-01]\n",
      " [8.79299223e-01 0.00000000e+00 9.89627540e-01 2.72493362e-01]\n",
      " [7.05092371e-01 2.08001435e-02 9.94321287e-01 9.86255169e-01]\n",
      " [8.21386993e-01 1.41731054e-01 1.00000000e+00 4.11078066e-01]\n",
      " [7.79396474e-01 4.20248508e-02 8.81117165e-01 1.22619539e-01]\n",
      " [7.22141802e-01 1.57837272e-02 1.00000000e+00 2.96794504e-01]\n",
      " [7.88498878e-01 8.10495988e-02 8.68767619e-01 1.46957546e-01]\n",
      " [3.87659669e-03 5.10641336e-02 5.61958671e-01 1.00000000e+00]], shape=(100, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "output_dict = model.signatures[\"serving_default\"](input_tensor)\n",
    "\n",
    "classes = output_dict[\"detection_classes\"][0]\n",
    "scores = output_dict[\"detection_scores\"][0]\n",
    "boxes = output_dict[\"detection_boxes\"][0]\n",
    "\n",
    "print(classes)\n",
    "print(scores)\n",
    "print(boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff7f015",
   "metadata": {},
   "source": [
    "> Q6. 아래의 full 버전 코드에 직접 주석을 달아보며 흐름을 파악해봅시다.\n",
    "\n",
    "### 추론 결과 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa2710d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "capture = cv2.VideoCapture(os.getenv('HOME') + '/OpenCV/bird.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    if capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "        break\n",
    "\n",
    "    input_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    input_tensor = tf.convert_to_tensor(input_img)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    output_dict = model.signatures[\"serving_default\"](input_tensor)\n",
    "\n",
    "    classes = output_dict[\"detection_classes\"][0]\n",
    "    scores = output_dict[\"detection_scores\"][0]\n",
    "    boxes = output_dict[\"detection_boxes\"][0]\n",
    "\n",
    "    height, width, _ = frame.shape\n",
    "    for idx, score in enumerate(scores):\n",
    "        if score > 0.7:\n",
    "            class_id = int(classes[idx])\n",
    "            box = boxes[idx]\n",
    "\n",
    "            x1 = int(box[1] * width)\n",
    "            y1 = int(box[0] * height)\n",
    "            x2 = int(box[3] * width)\n",
    "            y2 = int(box[2] * height)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), 255, 1)\n",
    "            cv2.putText(frame, str(class_id) + \":\" + str(float(score)), (x1, y1 - 5), cv2.FONT_HERSHEY_COMPLEX, 1.5, (0, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow(\"Object Detection\", frame)\n",
    "    if cv2.waitKey(33) == ord(\"q\"):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a346f8",
   "metadata": {},
   "source": [
    "## 정규표현식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2175306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item {\n",
      "  name: \"/m/01g317\"\n",
      "  id: 1\n",
      "  display_name: \"person\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(PATH_TO_LABELS, \"rt\") as f:\n",
    "    pb_classes = f.read().rstrip(\"\\n\").split(\"\\n\")\n",
    "\n",
    "    print(pb_classes[0])\n",
    "    print(pb_classes[1])\n",
    "    print(pb_classes[2])\n",
    "    print(pb_classes[3])\n",
    "    print(pb_classes[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa298d",
   "metadata": {},
   "source": [
    "> Q9. 아래의 예제(정규표현식을 활용해 입력 문자열에서 패턴 검출하기)를 수행하고, 주석을 달아보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fec8c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "with open(PATH_TO_LABELS, \"rt\") as f:\n",
    "    pb_classes = f.read().rstrip(\"\\n\").split(\"\\n\")\n",
    "    classes_label = dict()\n",
    "    \n",
    "    for i in range(0, len(pb_classes), 5):\n",
    "        pb_classId = int(re.findall(\"\\d+\", pb_classes[i + 2])[0])\n",
    "        pattern = 'display_name: \"(.*?)\"'\n",
    "        pb_text = re.search(pattern, pb_classes[i + 3])\n",
    "        classes_label[pb_classId] = pb_text.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaac523",
   "metadata": {},
   "source": [
    "> Q10. 아래의 코드는 텐서플로우를 활용한 객체 검출의 전체 코드입니다. 전체 순서를 파악해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1191f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "with open(PATH_TO_LABELS, \"rt\") as f:\n",
    "    pb_classes = f.read().rstrip(\"\\n\").split(\"\\n\")\n",
    "    classes_label = dict()\n",
    "\n",
    "    for i in range(0, len(pb_classes), 5):\n",
    "        pb_classId = int(re.findall(\"\\d+\", pb_classes[i + 2])[0])\n",
    "        pattern = 'display_name: \"(.*?)\"'\n",
    "        pb_text = re.search(pattern, pb_classes[i + 3])\n",
    "        classes_label[pb_classId] = pb_text.group(1)\n",
    "\n",
    "model = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "capture = cv2.VideoCapture(os.getenv('HOME') + '/OpenCV/bird.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    if capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "        break\n",
    "\n",
    "    input_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    input_tensor = tf.convert_to_tensor(input_img)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    output_dict = model.signatures[\"serving_default\"](input_tensor)\n",
    "\n",
    "    classes = output_dict[\"detection_classes\"][0]\n",
    "    scores = output_dict[\"detection_scores\"][0]\n",
    "    boxes = output_dict[\"detection_boxes\"][0]\n",
    "\n",
    "    height, width, _ = frame.shape\n",
    "    for idx, score in enumerate(scores):\n",
    "        if score > 0.7:\n",
    "            class_id = int(classes[idx])\n",
    "            box = boxes[idx]\n",
    "\n",
    "            x1 = int(box[1] * width)\n",
    "            y1 = int(box[0] * height)\n",
    "            x2 = int(box[3] * width)\n",
    "            y2 = int(box[2] * height)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), 255, 1)\n",
    "            cv2.putText(frame, classes_label[class_id] + \":\" + str(float(score)), (x1, y1 - 5), cv2.FONT_HERSHEY_COMPLEX, 1.5, (0, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow(\"Object Detection\", frame)\n",
    "    if cv2.waitKey(33) == ord(\"q\"):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
